# Envision
Computer Vision powered smart glasses for blind people


Problem Statement:
Visually challenged individuals face daily hurdles in identifying objects and navigating their surroundings independently. Additionally, they often lack accessible and personalized mental health support systems. Traditional methods of assistance may not always meet their unique needs. Therefore, there is a pressing need for a comprehensive solution that seamlessly integrates object detection capabilities with personalized mental health assistance, providing a user-friendly interface and human-like interaction.

Proposed Solution:
In response to the challenges faced by visually impaired individuals, we have devised a software solution, thereby providing comprehensive assistance tailored to their unique needs. This innovative technology harnesses the power of advanced algorithms to empower visually challenged individuals in navigating their surroundings and accessing personalized mental health support.

##Object Detection:
At the core of our solution lies a sophisticated object detection system, powered by OpenCV and PyTorch frameworks. OpenCV provides essential tools and functions for computer vision tasks, while PyTorch enables efficient training and deployment of deep learning models. Specifically, we utilize YOLO (You Only Look Once) algorithm, a state-of-the-art object detection model known for its speed and accuracy in real-time detection tasks. By leveraging YOLO, our system can identify and recognize various objects within the user's environment, facilitating seamless interaction with the physical world.

##Natural Language Processing (NLP):
Moreover, our solution incorporates advanced Natural Language Processing (NLP) capabilities, including Transformer models, to develop an intelligent voice-enabled assistant. We utilize pre-trained Transformer models such as BERT (Bidirectional Encoder Representations from Transformers) to understand and process user queries with high accuracy. This assistant serves as a constant companion to the visually impaired individual, offering intuitive navigation support and responding to user inquiries with empathy and understanding.

##User Interface:
To enhance accessibility and usability, our solution features a user-friendly interface developed using the QT framework. QT provides powerful tools for developing cross-platform applications with rich graphical user interfaces. Our interface includes intuitive navigation controls and auditory feedback, enabling visually impaired users to interact effortlessly with the software and hardware components.

Additional Feature:
In addition to object detection and personalized mental health assistance, we also integrated a chatbot to offer continuous mental health support to visually impaired individuals. This chatbot utilizes a combination of rule-based and machine learning approaches to provide relevant and timely responses to user queries, ensuring they have access to assistance whenever they need it.
##How to Use:
Clone the repository to your local machine.
Install the required dependencies using pip install -r requirements.txt.
Run the main application script.
Follow the on-screen instructions to calibrate the system and start using the Envision smart glasses.
##Contributors:
Sakthi Mahendran
Sachin Anandharaj
Kiran
##License:
This project is licensed under the MIT License - see the LICENSE file for details.
